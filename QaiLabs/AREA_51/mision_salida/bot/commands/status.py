"""
QAI HQ Bot â€” Comando /status
Lee STATUS.md del HQ y genera un resumen inteligente.
"""
import logging
from services.github_reader import github_reader
from services.llm_provider import get_llm

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = """Eres Nzero, el agente arquitecto de QAI Company. 
Tu tarea es resumir el STATUS del HQ digital para el Founder (Alejandro) quien te lee desde Telegram.

Reglas:
- Responde en espaÃ±ol
- MÃ¡ximo 15 lÃ­neas
- Usa emojis para secciones
- Resalta items ğŸ”´ (bloqueado) y ğŸŸ¡ (en proceso)
- Los items âœ… solo menciÃ³nalos si son recientes (Ãºltimos 3 dÃ­as)
- Formato: bullets concisos, sin tablas
- Al final, indica la fecha de Ãºltima actualizaciÃ³n del STATUS
"""


def handle_status() -> str:
    """Lee STATUS.md y genera resumen para Telegram."""
    logger.info("ğŸ“Š Comando /status ejecutado")

    # Leer STATUS.md desde GitHub
    content = github_reader.read_status()
    if not content:
        return "âŒ No pude leer STATUS.md desde el repositorio. Verifica el acceso."

    # Resumir con LLM
    llm = get_llm()
    prompt = f"Resume el siguiente STATUS del HQ digital:\n\n{content}"

    try:
        summary = llm.chat(prompt, system_instruction=SYSTEM_PROMPT)
        return f"ğŸ“Š *Estado del HQ* (via {llm.name})\n\n{summary}"
    except Exception as e:
        logger.error("âŒ Error al resumir STATUS: %s", e)
        # Fallback: extraer primeras lÃ­neas relevantes
        return _fallback_summary(content)


def _fallback_summary(content: str) -> str:
    """Resumen bÃ¡sico sin LLM (fallback)."""
    lines = content.split("\n")
    relevant = []
    for line in lines:
        stripped = line.strip()
        if any(marker in stripped for marker in ["ğŸ”´", "ğŸŸ¡", "ğŸŸ¢", "âœ…"]):
            relevant.append(stripped)
        if len(relevant) >= 10:
            break

    if relevant:
        return "ğŸ“Š *Estado del HQ* (modo fallback)\n\n" + "\n".join(relevant)
    return "ğŸ“Š STATUS cargado pero no pude generar un resumen."
